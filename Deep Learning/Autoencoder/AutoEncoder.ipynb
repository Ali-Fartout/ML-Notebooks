{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bfebf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # encoder\n",
    "        self.input = nn.Linear(784,512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.fc1 = nn.Linear(512,128)\n",
    "        self.fc2 = nn.Linear(128,32)\n",
    "        self.fc3 = nn.Linear(32,10)\n",
    "        \n",
    "        # decoder\n",
    "        self.up_fc1 = nn.Linear(10,32)\n",
    "        self.up_fc2 = nn.Linear(32,128)\n",
    "        self.up_fc3 = nn.Linear(128,512)\n",
    "        self.up_fc4 = nn.Linear(512,784)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.tanh(x) \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.tanh(x) \n",
    "        x = self.fc2(x)\n",
    "        x = self.tanh(x) \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    def decoder(self, x):\n",
    "        x = self.up_fc1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.up_fc2(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.up_fc3(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.up_fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0e9021b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(outputs, inputs, model_parameters):\n",
    "    mse_loss = nn.MSELoss()(outputs, inputs)\n",
    "    l2_penalty = 0.00001  * sum([(p**2).sum() for p in model_parameters])\n",
    "    loss = mse_loss + l2_penalty\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d619b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a040691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69a5e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, n_clusters, max_iter=100):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.centroids = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        initial_indices = torch.randperm(X.size(0))[:self.n_clusters]\n",
    "        self.centroids = X[initial_indices]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            labels = self._assign_clusters(X)\n",
    "            new_centroids = self._update_centroids(X, labels)\n",
    "            if torch.all(torch.eq(self.centroids, new_centroids)):\n",
    "                break\n",
    "\n",
    "            self.centroids = new_centroids\n",
    "\n",
    "    def _assign_clusters(self, X):\n",
    "        distances = torch.norm(X.unsqueeze(1) - self.centroids, dim=2)\n",
    "        return torch.argmin(distances, dim=1)\n",
    "\n",
    "    def _update_centroids(self, X, labels):\n",
    "        new_centroids = torch.zeros((self.n_clusters, X.size(1)), device=X.device)\n",
    "        for i in range(self.n_clusters):\n",
    "            new_centroids[i] = X[labels == i].mean(dim=0)\n",
    "        return new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4c8d4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = []\n",
    "targets = []\n",
    "for data in train_loader:\n",
    "    inputs, target = data\n",
    "    inputs = inputs.view(inputs.size(0), -1)\n",
    "    targets.append(target)\n",
    "    mnist_data.append(inputs)\n",
    "\n",
    "mnist_data = torch.cat(mnist_data, dim=0)\n",
    "targets = torch.cat(targets, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1040ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "kmeans.fit(mnist_data)\n",
    "\n",
    "cluster_assignments = kmeans._assign_clusters(mnist_data)\n",
    "final_centroids = kmeans.centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b2cd7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index: 0.35986997680043337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "ari = adjusted_rand_score(cluster_assignments.numpy(), targets.numpy())\n",
    "\n",
    "print(\"Adjusted Rand Index:\", ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "71c695ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss:0.6818821611374616\n",
      "Epoch 2, Loss:0.5853406475454569\n",
      "Epoch 3, Loss:0.5589586384445429\n",
      "Epoch 4, Loss:0.522802093309164\n",
      "Epoch 5, Loss:0.5091486037775874\n",
      "Epoch 6, Loss:0.5051126685753464\n",
      "Epoch 7, Loss:0.5013865369454026\n",
      "Epoch 8, Loss:0.4952262855827808\n",
      "Epoch 9, Loss:0.4898507927075028\n",
      "Epoch 10, Loss:0.48754627903997894\n",
      "Epoch 11, Loss:0.4206957118883729\n",
      "Epoch 12, Loss:0.3979386596918106\n",
      "Epoch 13, Loss:0.3889977409377694\n",
      "Epoch 14, Loss:0.38427083947509527\n",
      "Epoch 15, Loss:0.38122133507877587\n",
      "Epoch 16, Loss:0.3792967976734042\n",
      "Epoch 17, Loss:0.3778288224443793\n",
      "Epoch 18, Loss:0.3767986906483769\n",
      "Epoch 19, Loss:0.37581224898844956\n",
      "Epoch 20, Loss:0.37495533987879753\n",
      "Epoch 21, Loss:0.3670218983978033\n",
      "Epoch 22, Loss:0.3662135328456759\n",
      "Epoch 23, Loss:0.3659274549677968\n",
      "Epoch 24, Loss:0.36562790468484163\n",
      "Epoch 25, Loss:0.36531408231407403\n",
      "Epoch 26, Loss:0.36499581681489945\n",
      "Epoch 27, Loss:0.364659365992248\n",
      "Epoch 28, Loss:0.364328302565217\n",
      "Epoch 29, Loss:0.36399939545542\n",
      "Epoch 30, Loss:0.36366899665296076\n",
      "Epoch 31, Loss:0.3626652236804366\n",
      "Epoch 32, Loss:0.36252080930024383\n",
      "Epoch 33, Loss:0.3624673267543316\n",
      "Epoch 34, Loss:0.36242260085642336\n",
      "Epoch 35, Loss:0.36238527009934185\n",
      "Epoch 36, Loss:0.36234714147895575\n",
      "Epoch 37, Loss:0.3623092700108886\n",
      "Epoch 38, Loss:0.36227344914525744\n",
      "Epoch 39, Loss:0.3622362687975168\n",
      "Epoch 40, Loss:0.3621993605598807\n",
      "Epoch 41, Loss:0.3620710824295878\n",
      "Epoch 42, Loss:0.36205947993099685\n",
      "Epoch 43, Loss:0.362053326433897\n",
      "Epoch 44, Loss:0.36204850823432205\n",
      "Epoch 45, Loss:0.36204426929801703\n",
      "Epoch 46, Loss:0.36204027470648287\n",
      "Epoch 47, Loss:0.3620363236159086\n",
      "Epoch 48, Loss:0.36203257538080214\n",
      "Epoch 49, Loss:0.3620287279039621\n",
      "Epoch 50, Loss:0.36202493695020677\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "num_epochs = 50\n",
    "autoencoder.to(\"cuda\")\n",
    "\n",
    "lr_scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data in train_loader:\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.view(-1, 784).to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(inputs)\n",
    "        loss = custom_loss(outputs, inputs, autoencoder.parameters())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    lr_scheduler.step() \n",
    "    print(f\"Epoch {epoch+1}, Loss:{running_loss / (len(train_loader) / 12 )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b26b6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_encoded = []\n",
    "\n",
    "for data in train_loader:\n",
    "    inputs, _ = data\n",
    "    \n",
    "    inputs = inputs.view(-1, 784).to(\"cuda\")\n",
    "    output = autoencoder.encoder(inputs)\n",
    "    output = output.view(output.size(0), -1)  \n",
    "    mnist_data_encoded.append(output)\n",
    "\n",
    "mnist_data_encoded = torch.cat(mnist_data_encoded, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "083c6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "kmeans_encoded = KMeans(n_clusters=10)\n",
    "kmeans_encoded.fit(mnist_data_encoded)\n",
    "\n",
    "cluster_assignments_encoded = kmeans_encoded._assign_clusters(mnist_data_encoded)\n",
    "final_centroids_encoded = kmeans_encoded.centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "73349256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index: 3.115718604115946e-06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "ari = adjusted_rand_score(cluster_assignments_encoded.cpu(), targets.numpy())\n",
    "\n",
    "print(\"Adjusted Rand Index:\", ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab96875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
