{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "bfebf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # encoder\n",
    "        self.input = nn.Linear(784,512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.fc1 = nn.Linear(512,128)\n",
    "        self.fc2 = nn.Linear(128,32)\n",
    "        self.fc3 = nn.Linear(32,10)\n",
    "        \n",
    "        # decoder\n",
    "        self.up_fc1 = nn.Linear(10,32)\n",
    "        self.up_fc2 = nn.Linear(32,128)\n",
    "        self.up_fc3 = nn.Linear(128,512)\n",
    "        self.up_fc4 = nn.Linear(512,784)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.tanh(x) \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.tanh(x) \n",
    "        x = self.fc2(x)\n",
    "        x = self.tanh(x) \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    def decoder(self, x):\n",
    "        x = self.up_fc1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.up_fc2(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.up_fc3(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.up_fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "0e9021b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(outputs, inputs,pred,truth , model_parameters):\n",
    "    inputs = inputs.to('cuda:0')\n",
    "    outputs = outputs.to('cuda:0')\n",
    "    pred = pred.to('cuda:0')\n",
    "    truth = truth.to('cuda:0')\n",
    "    \n",
    "    # Find indices where truth is equal to pred\n",
    "    matching_indices = torch.nonzero(truth == pred)\n",
    "    non_matching = torch.nonzero(truth != pred)\n",
    "\n",
    "    same_labels =  torch.sum(torch.exp(- ((outputs[matching_indices] - inputs[matching_indices])).pow(2)))   / ((truth == pred).sum().item()+1)\n",
    "    dif_labels =   torch.sum((1 - torch.exp(- ((outputs[non_matching] - inputs[non_matching])).pow(2))))  / ((truth != pred).sum().item()+1)\n",
    "    weight_term =   same_labels * dif_labels\n",
    "    cmse_loss =  (weight_term * ((pred - truth) ** 2)).mean()\n",
    "    l2_penalty = 0.00001  * sum([(p**2).sum() for p in model_parameters])\n",
    "    loss = cmse_loss + l2_penalty\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "d619b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "9a040691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "69a5e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, n_clusters, max_iter=100):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.centroids = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        initial_indices = torch.randperm(X.size(0))[:self.n_clusters]\n",
    "        self.centroids = X[initial_indices]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            labels = self._assign_clusters(X)\n",
    "            new_centroids = self._update_centroids(X, labels)\n",
    "            if torch.all(torch.eq(self.centroids, new_centroids)):\n",
    "                break\n",
    "\n",
    "            self.centroids = new_centroids\n",
    "\n",
    "    def _assign_clusters(self, X):\n",
    "        distances = torch.norm(X.unsqueeze(1) - self.centroids, dim=2)\n",
    "        return torch.argmin(distances, dim=1)\n",
    "\n",
    "    def _update_centroids(self, X, labels):\n",
    "        new_centroids = torch.zeros((self.n_clusters, X.size(1)), device=X.device)\n",
    "        for i in range(self.n_clusters):\n",
    "            new_centroids[i] = X[labels == i].mean(dim=0)\n",
    "        return new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "4c8d4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = []\n",
    "targets = []\n",
    "for data in train_loader:\n",
    "    inputs, target = data\n",
    "    inputs = inputs.view(inputs.size(0), -1)\n",
    "    targets.append(target)\n",
    "    mnist_data.append(inputs)\n",
    "\n",
    "mnist_data = torch.cat(mnist_data, dim=0)\n",
    "targets = torch.cat(targets, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1040ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "\n",
    "# kmeans = KMeans(n_clusters=10)\n",
    "# kmeans.fit(mnist_data)\n",
    "\n",
    "# cluster_assignments = kmeans._assign_clusters(mnist_data)\n",
    "# final_centroids = kmeans.centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "a1d718f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_assignments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b2cd7af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# ari = adjusted_rand_score(cluster_assignments.numpy(), targets.numpy()) * 100\n",
    "\n",
    "# print(\"Adjusted Rand Index:\", f'{ari:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "71c695ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss:1534700.2554440196\n",
      "Epoch 2, Loss:915964.2574828997\n",
      "Epoch 3, Loss:876422.5500331289\n",
      "Epoch 4, Loss:1028448.3320081574\n",
      "Epoch 5, Loss:907792.7722969545\n",
      "Epoch 6, Loss:838096.2497204529\n",
      "Epoch 7, Loss:813265.9992728679\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "num_epochs = 7\n",
    "autoencoder.to(\"cuda\")\n",
    "\n",
    "lr_scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data in train_loader:\n",
    "        inputs, truth = data\n",
    "        inputs = inputs.view(-1, 784).to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(inputs)\n",
    "        pred  = autoencoder.encoder(inputs)\n",
    "        loss = custom_loss(outputs, inputs,pred.argmax(dim=1),truth, autoencoder.parameters())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    lr_scheduler.step() \n",
    "    print(f\"Epoch {epoch+1}, Loss:{running_loss / (len(train_loader) / 12 )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa49d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in train_loader:\n",
    "#         inputs, truth = data\n",
    "#         inputs = inputs.view(-1, 784).to(\"cuda\")\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = autoencoder(inputs)\n",
    "#         pred  = autoencoder.encoder(inputs)\n",
    "#         break\n",
    "        \n",
    "# inputs = inputs.to('cuda:0')\n",
    "# outputs = outputs.to('cuda:0')\n",
    "# pred = pred.to('cuda:0')\n",
    "# truth = truth.to('cuda:0')\n",
    "# pred = pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = 0\n",
    "# same_labels =  torch.sum(torch.exp(- ((outputs - inputs)).pow(2)))   / ((truth == pred).sum().item()+1)\n",
    "# dif_labels =   torch.sum((1 - torch.exp(- ((outputs - inputs)).pow(2))))  / ((truth != pred).sum().item()+1)\n",
    "# weight_term =   same_labels / dif_labels\n",
    "# cmse_loss =  (weight_term * ((pred - truth) ** 2)).mean()\n",
    "# l2_penalty = 0.00001  * sum([(p**2).sum() for p in autoencoder.parameters()])\n",
    "# loss = cmse_loss + l2_penalty\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518109a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = inputs.to('cuda:0')\n",
    "# outputs = outputs.to('cuda:0')\n",
    "# pred = pred.to('cuda:0')\n",
    "# truth = truth.to('cuda:0')\n",
    "# pred = pred.argmax(dim=1)\n",
    "# outputs\n",
    "# same_labels =  torch.exp(- ((outputs - inputs)).pow(2))  / (truth == pred).sum().item()\n",
    "# print(torch.exp(- ((outputs - inputs)).pow(2)))\n",
    "# print((truth == pred).sum().item()+1)\n",
    "\n",
    "# dif_labels =   torch.sum(1 - torch.exp(- ((outputs - inputs)).pow(2)))   / (truth != pred).sum().item()\n",
    "# weight_term = dif_labels * same_labels\n",
    "# cmse_loss = torch.mean(weight_term * ((pred - truth) ** 2))\n",
    "# print(cmse_loss)\n",
    "# l2_penalty = 0.00001  * sum([(p**2).sum() for p in model_parameters])\n",
    "# loss = cmse_loss + l2_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_encoded = []\n",
    "\n",
    "for data in train_loader:\n",
    "    inputs, _ = data\n",
    "    \n",
    "    inputs = inputs.view(-1, 784).to(\"cuda\")\n",
    "    output = autoencoder.encoder(inputs)\n",
    "    output = output.view(output.size(0), -1)  \n",
    "    mnist_data_encoded.append(output)\n",
    "\n",
    "mnist_data_encoded = torch.cat(mnist_data_encoded, dim=0)\n",
    "mnist_data_encoded.argmax(dim=1).shape , targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538aff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_encoded.argmax(dim=1)[0], targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "kmeans_encoded = KMeans(n_clusters=10)\n",
    "kmeans_encoded.fit(mnist_data_encoded)\n",
    "\n",
    "cluster_assignments_encoded = kmeans_encoded._assign_clusters(mnist_data_encoded)\n",
    "final_centroids_encoded = kmeans_encoded.centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73349256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "ari = adjusted_rand_score(cluster_assignments_encoded.cpu(), targets.numpy()) * 100\n",
    "\n",
    "print(\"Adjusted Rand Index:\", f'{ari:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab96875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
